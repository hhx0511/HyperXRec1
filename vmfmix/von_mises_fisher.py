import math
import torch
from torch.distributions.kl import register_kl

from vmfmix.ive import ive
from vmfmix.hyperspherical_uniform import HypersphericalUniform


class VonMisesFisher(torch.distributions.Distribution):

    arg_constraints = {'loc': torch.distributions.constraints.real,#loc æ˜¯æ–¹å‘ä¸­å¿ƒï¼Œè¦æ±‚æ˜¯å®æ•°å¼ é‡
                       'scale': torch.distributions.constraints.positive}#scale æ˜¯é›†ä¸­åº¦ï¼ˆÎºï¼‰ï¼Œå¿…é¡»æ˜¯æ­£æ•°ï¼›
    support = torch.distributions.constraints.real
    has_rsample = True#è¡¨ç¤ºæ”¯æŒå¯å¯¼é‡‡æ ·ï¼ˆé‡å‚æ•°åŒ–ï¼‰ï¼›
    _mean_carrier_measure = 0#æ˜¯ä¸€äº›åˆ†å¸ƒæ‰€éœ€çš„æ ‡å‡†å±æ€§ï¼Œå¯æš‚ä¸ç†ä¼šã€‚

    #E[x]=A(Îº)â‹…Î¼,ä»è¿™ä¸ªåˆ†å¸ƒä¸­é‡‡æ ·å¾ˆå¤šæ¬¡ï¼ŒæŠŠæ‰€æœ‰æ ·æœ¬åŠ èµ·æ¥å¹³å‡ï¼Œå¾—åˆ°çš„æ–¹å‘å‘é‡,Î¼ï¼šå•ä½å‘é‡æ–¹å‘ï¼ˆå‡å€¼æ–¹å‘ï¼‰,ğ´(ğœ…)ä¸€ä¸ªå°äºç­‰äº1çš„ç¼©æ”¾ç³»æ•°ï¼Œå†³å®šâ€œæ ·æœ¬å¹³å‡å€¼â€è·ç¦»å•ä½çƒé¢ä¸­å¿ƒçš„è¿œè¿‘
    #vMF åˆ†å¸ƒçš„å‡å€¼æ˜¯ä¸€ä¸ªä¸å†ä½äºå•ä½çƒé¢ä¸Šçš„å‘é‡ï¼Œè€Œæ˜¯ä»åŸç‚¹æŒ‡å‘ Î¼ æ–¹å‘ï¼Œä½†é•¿åº¦æ˜¯ A(Îº)ï¼Œè¶Šé›†ä¸­è¶Šæ¥è¿‘å•ä½é•¿åº¦ã€‚
    @property#mean è¿‘ä¼¼ä¸ºï¼šå‡å€¼æ–¹å‘ loc Ã— æŸä¸ªæ¯”ä¾‹ï¼ˆç”±è´å¡å°”å‡½æ•°è®¡ç®—ï¼Œå†³å®šé›†ä¸­ç¨‹åº¦ï¼‰
    def mean(self):
        return self.loc * (ive(self.__m / 2, self.scale) / ive(self.__m / 2 - 1, self.scale))

    @property#stddev æ˜¯ Îºï¼Œåœ¨ vMF åˆ†å¸ƒä¸­æ²¡æœ‰ä¼ ç»Ÿæ„ä¹‰ä¸Šçš„æ ‡å‡†å·®ï¼Œç”¨é›†ä¸­åº¦ä»£æ›¿ã€‚
    def stddev(self):
        return self.scale

    def __init__(self, loc, scale, validate_args=None):
        self.dtype = loc.dtype
        self.loc = loc#å•ä½å‘é‡ï¼Œè¡¨ç¤ºåˆ†å¸ƒä¸­å¿ƒï¼›
        self.scale = scale#æµ“åº¦å‚æ•° Îºï¼Œè¶Šå¤§è¡¨ç¤ºè¶Šé›†ä¸­ï¼›
        self.device = loc.device
        self.__m = loc.shape[-1]#ç»´åº¦ï¼›
        #æ„é€ ä¸€ä¸ªå½¢å¦‚ (1,0,0,â€¦,0) çš„å•ä½å‘é‡ï¼Œç»´åº¦å’Œ loc ä¸€æ ·ã€‚é»˜è®¤çš„é‡‡æ ·ä¸­å¿ƒæ–¹å‘ã€‚
        #z çš„æ–¹å‘é›†ä¸­åœ¨ loc å‘¨å›´	è¶Šé è¿‘ loc è¶Šå¯èƒ½è¢«é‡‡æ ·åˆ°ï¼ˆå— Îº æ§åˆ¶ï¼‰ï¼Œé‡å‚æ•°é‡‡æ ·å…¬å¼å¹¶ä¸å®¹æ˜“ç›´æ¥å®ç°ï¼Œå…ˆåœ¨ä¸€ä¸ªå›ºå®šæ–¹å‘ï¼ˆæ¯”å¦‚ (1,0,...,0)ï¼Œæˆ‘ä»¬å«å®ƒâ€œåŒ—æâ€ï¼‰é‡‡æ ·ï¼ŒæŠŠè¿™ä¸ªæ–¹å‘ä¸Šçš„æ ·æœ¬é€šè¿‡ æ—‹è½¬ å˜æ¢å¯¹é½åˆ°ç”¨æˆ·æŒ‡å®šçš„ loc æ–¹å‘
        #Householder å˜æ¢æ˜¯ä¸€ç§å°†å‘é‡ a æ˜ å°„åˆ°å‘é‡ b çš„æ­£äº¤çº¿æ€§å˜æ¢ï¼ŒH(x)=xâˆ’2â‹…âŸ¨x,uâŸ©â‹…uå…¶ä¸­u= âˆ¥aâˆ’bâˆ¥/aâˆ’bï¼Œè¿™ä¸ªå˜æ¢å¯ä»¥æŠŠæ‰€æœ‰è½åœ¨ä»¥ e1 ä¸ºä¸­å¿ƒçš„çƒé¢åˆ†å¸ƒçš„ç‚¹æ—‹è½¬åˆ° loc ä¸Šï¼Œä¸æ”¹å˜å®ƒä»¬çš„æ¨¡é•¿æˆ–åˆ†å¸ƒç»“æ„ã€‚
        self.__e1 = (torch.Tensor([1.] + [0] * (loc.shape[-1] - 1))).to(self.device)#ç”¨æ¥åš Householder å˜æ¢çš„â€œåŒ—æå‘é‡â€ï¼ˆé»˜è®¤æœå‘ï¼‰ï¼›

        super(VonMisesFisher, self).__init__(self.loc.size(), validate_args=validate_args)#.loc.size() æ˜¯ (B, D)ï¼Œè¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ª**â€œæ‰¹é‡åˆ†å¸ƒâ€**ï¼ˆå³ä½ æ„é€ äº† B ä¸ª vMF åˆ†å¸ƒï¼Œæ¯ä¸ªæœ‰ D ç»´ï¼‰ã€‚
    def sample(self, shape=torch.Size()):                                                #å¦‚æœä½ æ²¡æœ‰ä¼  shapeï¼Œå®ƒå°±æ˜¯ torch.Size()ï¼Œå³ []è¿™è¡¨ç¤ºå¯¹ æ¯ä¸ªåˆ†å¸ƒé‡‡ 1 ä¸ªæ ·æœ¬
        with torch.no_grad():                                                            #æ¯ä¸ª vMF(ğœ‡ğ‘–,ğœ…ğ‘–)åˆ†å¸ƒæ˜¯åœ¨å•ä½çƒé¢ ğ‘†ğ·âˆ’1âŠ‚ğ‘…ğ·ä¸Šçš„æ¦‚ç‡åˆ†å¸ƒã€‚
            return self.rsample(shape)

    def rsample(self, shape=torch.Size()):
        #è¾“å…¥ shape ç”¨äºæŒ‡å®šé‡‡æ ·çš„æ ·æœ¬æ•°é‡ã€‚å¦‚æœä¼ å…¥çš„æ˜¯æ•´æ•°ï¼Œä¼šè½¬æ¢æˆ torch.Size ç±»å‹ã€‚
        shape = shape if isinstance(shape, torch.Size) else torch.Size([shape])
        #é‡‡æ ·ä¸»æ–¹å‘ç»´åº¦çš„ wï¼Œå¯¹åº”çš„æ˜¯ä½ åœ¨ loc æ–¹å‘ä¸Šçš„æŠ•å½±åˆ†é‡ï¼Œå€¼åœ¨ [-1, 1] ä¹‹é—´ï¼Œæ§åˆ¶é‡‡æ ·ç‚¹è·ç¦» loc çš„â€œé è¿‘ç¨‹åº¦â€ï¼Œw â‰ˆ 1ï¼šé‡‡æ ·ç‚¹é è¿‘æ–¹å‘ä¸­å¿ƒï¼ˆÎ¼ï¼‰ï¼Œw â‰ˆ 0ï¼šé‡‡æ ·ç‚¹é è¿‘èµ¤é“ï¼Œw â‰ˆ -1ï¼šè¿œç¦»æ–¹å‘ä¸­å¿ƒ
        # æ ¹æ®å½“å‰çƒé¢çš„ç»´åº¦ m å†³å®šé‡‡ç”¨å“ªç§æ–¹å¼é‡‡æ ·å¾„å‘å˜é‡ wï¼š
        #å¦‚æœæ˜¯åœ¨ 3 ç»´ç©ºé—´ï¼ˆSÂ²ï¼‰ï¼Œä½¿ç”¨ä¼˜åŒ–çš„ __sample_w3 æ–¹æ³•ï¼›
        #å¦åˆ™ä½¿ç”¨æ›´é€šç”¨ä½†æ•ˆç‡è¾ƒä½çš„ __sample_w_rej æ‹’ç»é‡‡æ ·ï¼ˆrejection samplingï¼‰æ–¹æ³•ã€‚
        w = self.__sample_w3(shape=shape) if self.__m == 3 else self.__sample_w_rej(shape=shape)
        #é‡‡æ ·æ­£äº¤æ–¹å‘çš„å‘é‡ vï¼Œè¿™æ˜¯é‡‡æ ·â€œçƒé¢ä¸Šé™¤äº†ä¸»æ–¹å‘ä»¥å¤–çš„åˆ†é‡â€ï¼Œä¹Ÿå°±æ˜¯æ­£äº¤äº (1, 0, ..., 0) çš„å•ä½å‘é‡ã€‚
        #å…ˆç”Ÿæˆ shape ä¸º [B, D] çš„é«˜æ–¯å‘é‡ï¼ˆé›¶å‡å€¼æ­£æ€ï¼‰ï¼Œ.transpose(0, -1)[1:] å»æ‰ç¬¬ä¸€ç»´ï¼ˆä¹Ÿå°±æ˜¯ (1, 0, ..., 0) çš„æ–¹å‘ï¼‰ï¼Œå†è½¬å›æ¥ï¼Œå¾—åˆ° v.shape = [B, D-1]
        v = (torch.distributions.Normal(0, 1).sample(
            shape + torch.Size(self.loc.shape)).to(self.device).transpose(0, -1)[1:]).transpose(0, -1)
        v = v / v.norm(dim=-1, keepdim=True)#å½’ä¸€åŒ–ï¼Œç¡®ä¿å•ä½æ¨¡
        #æ‹¼æˆå•ä½å‘é‡ xï¼ˆæ–¹å‘åœ¨ (1,0,...,0) é™„è¿‘ï¼‰
        w_ = torch.sqrt(torch.clamp(1 - (w ** 2), 1e-10))#w: æ­£å‘ä¸»è½´åˆ†é‡ï¼ˆé è¿‘ä¸­å¿ƒ
        x = torch.cat((w, w_ * v), -1)#w_ * v: æ­£äº¤æ–¹å‘ä¸Šåˆ†é‡ï¼ˆæ§åˆ¶å›´ç»•ä¸­å¿ƒçš„æ•£å¸ƒï¼‰ï¼›æ‹¼æ¥ä¹‹åçš„ xï¼šæ˜¯ä¸€ä¸ªå®Œæ•´çš„å•ä½å‘é‡ï¼Œshape æ˜¯ [128, m]ï¼Œä½†æ˜¯æ–¹å‘æ˜¯å›´ç»• (1, 0, ..., 0) çš„ï¼Œä¸æ˜¯å›´ç»•ä½ çœŸæ­£çš„ loc
        # ç¬¬äº”æ­¥ï¼šç”¨ Householder æ—‹è½¬å°† x è½¬åˆ° loc
        z = self.__householder_rotation(x)#ç”¨ Householder æŠŠ x è½¬åˆ° locï¼Œæœ€ç»ˆ z å°±æ˜¯ä½ è¦çš„é‡‡æ ·ç‚¹ï¼

        return z.type(self.dtype)

    def __sample_w3(self, shape):
        #å¸Œæœ›é‡‡æ ·çš„â€œæ ·æœ¬æ•°é‡â€ä¸ Îºï¼ˆscaleï¼‰å‚æ•°çš„ shape æ‹¼æ¥ï¼Œç”Ÿæˆæœ€ç»ˆé‡‡æ ·å¼ é‡çš„ shapeã€‚
        shape = shape + torch.Size(self.scale.shape)#shape = torch.Size([32])          # ä½ å¸Œæœ›é‡‡æ · 32 ä¸ªæ ·æœ¬
        u = torch.distributions.Uniform(0, 1).sample(shape).to(self.device)
        self.__w = 1 + torch.stack([torch.log(u), torch.log(1 - u) - 2 * self.scale], dim=0).logsumexp(0) / self.scale
        return self.__w

    def __sample_w_rej(self, shape):
        #é‡‡æ ·ä¸€ä¸ªå˜é‡ wï¼Œå®ƒæ˜¯ï¼šåœ¨å•ä½çƒé¢ä¸Šï¼Œæ²¿ç€ä¸»æ–¹å‘ Î¼ çš„åˆ†é‡ï¼Œå³w=cos(Î¸)âˆˆ[âˆ’1,1]ï¼Œç”¨äºæ„é€ çƒé¢é‡‡æ ·ç‚¹ã€‚
        c = torch.sqrt((4 * (self.scale ** 2)) + (self.__m - 1) ** 2)#è®¡ç®—å¸¸æ•° ğ‘=æ ¹å·ä¸‹[4ğœ…2+(ğ‘šâˆ’1)2],è¿™æ˜¯åç»­ç”¨äºæ„é€ æ‹’ç»é‡‡æ · proposal çš„å‚æ•°
        b_true = (-2 * self.scale + c) / (self.__m - 1)#çœŸå®è®¡ç®—çš„ bï¼Œç”¨äºæ„é€  proposal åˆ†å¸ƒçš„åç§»é¡¹

        # using Taylor approximation with a smooth swift from 10 < scale < 11
        # to avoid numerical errors for large scale
        b_app = (self.__m - 1) / (4 * self.scale)#b_app æ˜¯ Taylor è¿‘ä¼¼ä¸‹çš„ç®€åŒ–ç‰ˆï¼ˆå½“ Îº éå¸¸å¤§æ—¶ï¼Œé¿å…æ•°å€¼ç²¾åº¦é—®é¢˜ï¼‰
        #æ§åˆ¶ä» Îº = 10 åˆ° 11 ä¹‹é—´çš„â€œå¹³æ»‘åˆ‡æ¢â€ç³»æ•° sï¼Œs ä»‹äº 0~1ï¼Œç”¨äºåœ¨ b_app å’Œ b_true ä¹‹é—´å¹³æ»‘æ’å€¼
        #scale < 10 â†’ s = 0 â†’ ä½¿ç”¨ b_trueï¼›scale > 11 â†’ s = 1 â†’ ä½¿ç”¨ b_app
        s = torch.min(torch.max(torch.tensor([0.], device=self.device),
                                self.scale - 10), torch.tensor([1.], device=self.device))
        #å¾—åˆ°æœ€ç»ˆä½¿ç”¨çš„ bï¼Œåœ¨ b_app å’Œ b_true ä¹‹é—´å¹³æ»‘æ’å€¼ï¼Œé¿å… Îº è¾ƒå¤§æ—¶æ•°å€¼ä¸ç¨³å®š
        b = b_app * s + b_true * (1 - s)
        #è¿™æ˜¯ Wood é‡‡æ ·ä¸­ç”¨äº proposal çš„ä¸­é—´å˜é‡ a
        a = (self.__m - 1 + 2 * self.scale + c) / 4
        #è¿™æ˜¯æ‹’ç»é‡‡æ ·ä¸­çš„ normalization å¸¸æ•° dï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦æ¥å—æŸä¸ªæ ·æœ¬
        d = (4 * a * b) / (1 + b) - (self.__m - 1) * math.log(self.__m - 1)
        #ç®€å•çš„ debug æ£€æŸ¥ï¼Œé˜²æ­¢ a ä¸º NaNï¼ˆÎº ç‰¹åˆ«å¤§æ—¶å¯èƒ½å‡ºé”™ï¼‰
        if torch.isnan(a).any():
            print(1)
        #çœŸæ­£æ‰§è¡Œæ‹’ç»é‡‡æ ·å¾ªç¯ __while_loop(...) æ¥é‡‡æ · (e, w)ï¼Œå¹¶å°†ç»“æœç¼“å­˜
        self.__b, (self.__e, self.__w) = b, self.__while_loop(b, a, d, shape)
        return self.__w#è¿”å›æœ€ç»ˆé‡‡æ ·å¾—åˆ°çš„ w å€¼ï¼Œshape ä¸€èˆ¬æ˜¯ [B, 1]ï¼Œç”¨äºåˆæˆçƒé¢é‡‡æ ·å‘é‡

    #æ‹’ç»é‡‡æ ·ï¼ˆRejection Samplingï¼‰ï¼Œä»ä¸€ä¸ªå®¹æ˜“é‡‡æ ·çš„â€œæè®®åˆ†å¸ƒâ€ä¸­é‡‡æ ·ï¼Œç„¶åæ ¹æ®æ¦‚ç‡å†³å®šæ˜¯å¦æ¥å—è¯¥æ ·æœ¬ã€‚
    def __while_loop(self, b, a, d, shape):

        b, a, d = [e.repeat(*shape, *([1] * len(self.scale.shape))) for e in (b, a, d)]
        w, e, bool_mask = torch.zeros_like(b).to(self.device), torch.zeros_like(
            b).to(self.device), (torch.ones_like(b) == 1).to(self.device)

        shape = shape + torch.Size(self.scale.shape)

        count = 0
        while bool_mask.sum() != 0:
            e_ = torch.distributions.Beta((self.__m - 1) / 2, (self.__m - 1) /
                                          2).sample(shape[:-1]).reshape(shape).to(self.device)
            u = torch.distributions.Uniform(0, 1).sample(shape).to(self.device)

            w_ = (1 - (1 + b) * e_) / (1 - (1 - b) * e_)
            t = (2 * a * b) / (1 - (1 - b) * e_)

            accept = ((self.__m - 1) * t.log() - t + d) > torch.log(u)
            reject = ~accept if torch.__version__ >= "1.2.0" else 1 - accept

            w[bool_mask * accept] = w_[bool_mask * accept]
            e[bool_mask * accept] = e_[bool_mask * accept]

            bool_mask[bool_mask * accept] = reject[bool_mask * accept]
            count += 1
            # if count > 10:
            #     print(1)
        # print(count)
        return e, w

    def __householder_rotation(self, x):
        u = (self.__e1 - self.loc)
        u = u / (u.norm(dim=-1, keepdim=True) + 1e-5)
        z = x - 2 * (x * u).sum(-1, keepdim=True) * u
        return z

    def entropy(self):
        output = - self.scale * ive(self.__m / 2, self.scale) / ive((self.__m / 2) - 1, self.scale)

        return output.view(*(output.shape[:-1])) + self._log_normalization()

    def log_prob(self, x):
        return self._log_unnormalized_prob(x) - self._log_normalization()

    def _log_unnormalized_prob(self, x):
        output = self.scale * (self.loc * x).sum(-1, keepdim=True)

        return output.view(*(output.shape[:-1]))

    def _log_normalization(self):
        output = - ((self.__m / 2 - 1) * torch.log(self.scale) - (self.__m / 2) * math.log(2 * math.pi) - (
            self.scale + torch.log(ive(self.__m / 2 - 1, self.scale))))

        return output.view(*(output.shape[:-1]))


@register_kl(VonMisesFisher, HypersphericalUniform)
def _kl_vmf_uniform(vmf, hyu):
    return - vmf.entropy() + hyu.entropy()
